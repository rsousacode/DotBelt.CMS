version: '3.8'

services:
  llama-server:
    
    image: ghcr.io/ggerganov/llama.cpp:server
    volumes:
      - ./AI/models/7B:/models
    environment:
      LLAMA_ARG_MODEL: /models/mistral-7b-instruct-v0.2.Q8_0.gguf
      LLAMA_ARG_CTX_SIZE: 4096
      LLAMA_ARG_N_PARALLEL: 2
      LLAMA_ARG_ENDPOINT_METRICS: 0  
      LLAMA_ARG_PORT: 8080
    ports:
      - "8000:8080"
